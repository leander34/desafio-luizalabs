1. Titulo do projeto.
2. Falar em poucas palavras sobre o projeto.
3. O que √© necessario para rodar o projeto
   1. docker
   2. rodar tal comando
   3. ai entrar no minIo
4. Como rodar o projeto
5. Como deve ficar o .env de cada pasta
6. Como executar os teste
   1. Entre em cada pasta e execute o comando
   2. colar - comando para executar teste na api, comando para executar os teste no worker tal
7. Chamar para api usando CURL
8. no retorna da api tal adicionei mais um campo pensando nisso e naquilo
9.  Tecnilogias utilizadas
10. Estrutura do Projeto (pastas e c√≥digo)
11. Colocar imagem da estrutra
12. Decis√µes T√©cnicas e Arquiteturais
   1. usei tal coisa por que Facilita consultas complexas no MySQL.
Seguran√ßa com valida√ß√£o de dados embutida.
Melhor DX (Developer Experience) para manuten√ß√£o do c√≥digo.
   1. usei principos de solid e clean arquitectura poq isso permite um c√≥digo mais testavel, extensivel e manutenivel
   2. optei pelo Fastify no back-end pela performance e suporte a valida√ß√£o nativa.
   3. obtei por usar um processo em microsservicoes pq isso permite que eu possa adicionar mais processo ao fluxo e processar as mensagens em qualquer lingguem
   4. usei redis para cachar os dados mais frequentemente consultados, pq isso deixa api mais rapida, consome menos recurso do banco e melhora a experiencia de uso
   5. use o rabbitMQ pq
   6. dividi em dois microsservi√ßos pois assim se exisir mais um worker que processa aquele arquivo e gera outra saida e facil de adicionar
   7. use o prisma pq
   8. use o docker pq permite criar ambientes isolado e que rodem em qualquer maquina ...
   9.  usei MinIo pq ele permite ...
1.  Possiveis Melhorias Futuras (Demonstra vis√£o e planejamento!)
2.  Autor





### DESAFIO TECNICO LUZIA LABS
# üèó Processamento de Arquivos Desnormalizados com Streams e Microservi√ßos

üöÄ Projeto desenvolvido para processar arquivos desnormalizados em formato TXT de forma eficiente, otimizando a leitura e escrita por meio de streams e distribuindo a carga entre microsservi√ßos para garantir escalabilidade e desempenho.

![Tela Inicial](images/2.png)

----------------------------
# üõ† Tecnologias Utilizadas

üîπ Back-end:
Node.js: Ideal para opera√ß√µes que utilizam streams e entrada/sa√≠da de dados.
Fastify: APIs leves e r√°pidas. Melhor suporte ao TypeScript. Alto modularidade e isolamento de escopo com plugins.
Streams nativas do Node.js: para processar arquivos sem sobrecarregar a mem√≥ria.
Prisma ORM: (armazenamento otimizado)

üîπ Infraestrutura:
Docker + Docker Compose: para facilitar a orquestra√ß√£o dos servi√ßos.
Redis: cache para otimizar buscas frequentes.
RabbitMQ: mensageria para distribuir tarefas entre os workers.
MySQL: Banco de dados relacional utilizado para armazenar dados estruturados.
MinIo: Armazenamento de objetos auto-hospedado e totalmente compativel com o s3. Ideal para ambientes de desenvolvimento.

üîπ Testes:
Vitest: testes unit√°rios e de integra√ß√£o
Supertest: testes de API


Escolhi essas tecnlogias por que elas combinam....
----------------------------



optei por um ter um campo quantity para processar possiveis produtos com mesmo valor em um mesmo pedido para 
Perguntas
por que usar um orm








-------------------------------------
üîç Fluxo de Processamento
1Ô∏è‚É£ O usu√°rio faz upload do arquivo CSV.
2Ô∏è‚É£ O sistema processa linha por linha usando streams (sem carregar o arquivo inteiro na RAM).
3Ô∏è‚É£ Cada linha √© enviada para um microservi√ßo via RabbitMQ para processamento ass√≠ncrono.
4Ô∏è‚É£ Os resultados s√£o armazenados no MySQL.

Fluxo de Dados
Upload de Arquivo: O usu√°rio envia um arquivo desnormalizado via API Fastify.
Armazenamento de Arquivos: O arquivo √© enviado para o MinIO para ser armazenado e acessado posteriormente.
Armazenamento do arquivo: O arquivo √© salvo usando em um storage s3 complatible auto-hospodedo

Processamento com Streams: O arquivo √© lido em chunks e os dados s√£o processados utilizando Streams.
Enfileiramento com RabbitMQ: As partes do arquivo processado s√£o enviadas para RabbitMQ, que distribui as tarefas entre os workers dispon√≠veis.
Armazenamento e Cache: Dados estruturados s√£o armazenados no MySQL e cacheados no Redis para otimizar consultas.






 Melhorias Futuras
üìå Adi√ß√£o de suporte a outros formatos de arquivo (JSON, XML).
üìå Monitoramento de fila no Prometheus + Grafana.



# üöÄ 3. Como Rodar o Projeto
- Ter docker instalado na maquina.
- Preencher as variaveis de ambiente (descomente o arquivo **.env.example** para maior facilidade). Essas s√£o as pastas que prencis√£o de configurar as variaveis de ambiente:
  - api/.env
  - workers/process-files/.env
  - workers/process-rows/.env
- **importante** Acessar portal do Minio no navegador (http://localhost:9001) para criar as API KEYs.
- Colocar as API KEYs no **.env** da **api** e do **workers/process-files**
 
Abaixo 

## PASSO A PASSO DETALHADO


üèó 6. Decis√µes T√©cnicas e Arquiteturais



 1. Melhorias Futuras

# üîç Testes
O projeto utiliza Vitest para testes automatizados, garantindo que todas as funcionalidades estejam funcionando corretamente antes de qualquer altera√ß√£o significativa no c√≥digo. Para rodar os testes, basta executar:

docker exec

### Configura√ß√£o variaveis de ambiente
Essas s√£o variaveis que precisam estar ativas
Voc√™ pode renomeada a pasta "**.env.example**" para "**.env**"

üîë Pasta **api**
DB_HOST: Endere√ßo do banco de dados MySQL.
DB_USER: Usu√°rio do banco de dados.
DB_PASSWORD: Senha do banco de dados.
REDIS_HOST: Endere√ßo do servidor Redis.
RABBITMQ_URL: URL do RabbitMQ.
MINIO_ENDPOINT: Endpoint do MinIO.
API_KEY: Chave de autentica√ß√£o para a API.





### Entre em cada container e execute o comando
No **container da API** execute o seguinte comando:
```bash
   docker exec it npm run test
```

No **container do worker-process-files** execute o seguinte comando:
```bash
   docker exec -it npm run test
```

No **container do worker-process-rows** execute o seguinte comando:
```bash
   docker exec -it npm run test
```
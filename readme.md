### DESAFIO T√âCNICO LUZIA LABS
# üèó Processamento de Arquivos Desnormalizados com Streams e Microservi√ßos


üöÄ Projeto desenvolvido para processar arquivos desnormalizados em formato .txt de forma eficiente, otimizando a leitura e escrita por meio de streams e distribuindo a carga entre microsservi√ßos para garantir escalabilidade e desempenho.

Decidi desenvolver o sistema em microsservi√ßos, pois isso possibilita o processamento de uma grande quantidade de dados, de maneira mais perform√°tica e distribu√≠da, evitando sobrecarga em um √∫nico servi√ßo. Na sess√£o de arquitetura existe uma **Imagem do System Design** que ilustra em mais detalhes como funciona todo fluxo de processamento do arquivo e como os microsservi√ßos foram estruturados.


# Como Rodar o Projeto üöÄ
## üìå Pr√©-requisitos
1. Ter o **Docker** instalado na m√°quina.
2. Preencher as vari√°veis de ambiente (renomeie o arquivo **.env.example** de cada pasta para **.env** maior facilidade). Fa√ßa as altera√ß√µes nos seguintes arquivos:
  - `./api/.env`
  - `./workers/process-files/.env`
  - `./workers/process-rows/.env `
3. **Importante** Para adicionar as vari√°veis **STORAGE_SECRET_KEY** e **STORAGE_BUCKET_NAME** acessar portal do MinIO no navegador (http://localhost:9001) para criar as API KEYs. Para acessar essa URL o container j√° deve estar rodando. Veremos como fazer isso no pr√≥ximo passo.
   
## Comandos Para Rodar o Projeto
1. Descomente os arquivos **.env.example**
2. Execute o seguinte comando `docker-compose up -d --build`
3. Como os container rodando, precisamos de mais um vari√°vel ambiente
4. Acesse o portal do MinIO no http://localhost:9001, no campo username digite "minioadmin" e no campo password "minioadmin".
5. Logando no portal, visualize o menu lateral esquerdo e clique no item "Access Keys".
6. Clique no bot√£o com texto "Create access key" que fica do lado direito da tela.
7. Clique em "Create".
8. Copie a "Access Key" e "Secret key".
9. Coloque esses dados no **.env** da `./api/.env` e no `./workers/process-files/.env`
10. Ser√° necess√°rio rebuildar a **api** e o **worker process files**
11. Rode o comando `docker-compose up -d --build` para subir todos os container novamente.


## üîë Como deve ficar o .env de cada pasta
### `./api/.env`
```bash
   NODE_ENV="development"
   DATABASE_URL="mysql://root:rootpassword@mysql:3306/desafio_labs" 
   RABBITMQ_URL="amqp://user:password@rabbitmq:5672"
   PORT=3000
   QUEUE_PROCESS_FILES="PROCESS.FILES"
   QUEUE_PROCESS_ROWS="PROCESS.ROWS"

   STORAGE_PROVIDER="MINIO"
   STORAGE_ENDPOINT="http://minio:9000"
   STORAGE_PORT="9000"
   STORAGE_ACCESS_KEY="SUA_ACCESS_KEY_GERADA_NO_PORTAL_MINIO"
   STORAGE_SECRET_KEY="SUA_SECRET_KEY_GERADA_NO_PORTAL_MINIO"
   STORAGE_BUCKET_NAME="desafio-labs"        
   STORAGE_REGION="us-east-1"

   REDIS_HOST="redis"
   REDIS_PORT=6379
   REDIS_DB=0
```
### `./workers/process-files/.env`

```bash
   NODE_ENV="development"
   RABBITMQ_URL="amqp://user:password@rabbitmq:5672"
   QUEUE_NAME="PROCESS.FILES"
   ROW_PROCESSING_QUEUE="PROCESS.ROWS"
   API_URL="http://api:3000"

   STORAGE_PROVIDER="MINIO"
   STORAGE_ENDPOINT="http://minio:9000"
   STORAGE_PORT="9000"
   STORAGE_ACCESS_KEY="SUA_ACCESS_KEY_GERADA_NO_PORTAL_MINIO"
   STORAGE_SECRET_KEY="SUA_SECRET_KEY_GERADA_NO_PORTAL_MINIO"
   STORAGE_BUCKET_NAME="desafio-labs"
   STORAGE_REGION="us-east-1"
```

### `./workers/process-rows/.env`

```bash
   NODE_ENV="development"
   RABBITMQ_URL="amqp://user:password@rabbitmq:5672"
   QUEUE_NAME="PROCESS.ROWS"
   API_URL="http://api:3000"
```
## ‚úÖ Como executar os testes
### Para executar os testes da API:
Para gerar arquivos de coverage `docker exec -it api-s3kzfsoz34 npm run test:coverage`
Para apenas rodar os testes `docker exec -it api-s3kzfsoz34 npm run test`

### Para executar os testes do worker-process-files:
Para gerar arquivos de coverage `docker exec -it worker-process-files-s3kzfsoz34 npm run test:coverage`
Para apenas rodar os testes `docker exec -it worker-process-files-s3kzfsoz34 npm run test:coverage`

### Para executar os testes do worker-process-rows:
Para gerar arquivos de coverage `docker exec -it worker-process-rows-s3kzfsoz34 npm run test:coverage`
Para apenas rodar os testes `docker exec -it worker-process-rows-s3kzfsoz34 npm run test:coverage`

# Enviar requisi√ß√µes para API usando CURL
### Endpoint GET `/files/order`
Endpoint usado para fazer upload dos arquivos .txt
Formatos validos: Apenas ".txt"
```bash
   curl -X GET http://localhost:3000/users/orders
```
### Endpoint `/users/orders`
Endpoint de retorno dos dados normalizados em JSON
```bash

   curl -X POST http://localhost:3000/files/order \
     -F "arquivo=@caminho/do/arquivo.txt"

```
 Alguns filtros dispon√≠veis:
- start_date: '2021-06-02' - Formato -> 'YYYY-MM-DD'
- end_date: '2021-10-10' - Formato -> 'YYYY-MM-DD'
- order_id: 1
Existe valida√ß√£o de formato para os campos "start_date" e "end_date"
Por exemplo -> formato inv√°lido: DD/MM/YYYY
Caso voc√™ envie uma data com valores de dia ou m√™s n√£o permidos como por exemplo 2021-04-32, o sistema converte essa data para 2021-05-01. Vale para o m√™s tamb√©m.
Para enviar com os filtros tente:
```bash
   curl -X GET "http://localhost:3000/users/orders?start_date=2021-05-10&end_date=2021-07-10"
```
Voc√™ pode ter notado que adicionei um novo campo "**quantity**" que representa a quantidade de um produto no **pedido**. Essa quantidade somente ser√° incrementa se o campo "**order_id**", "**product_id**" e "**value**" foram id√™nticos. Isso n√£o acontece nesses arquivos, mas pode ser que, em algum momento, existam linhas em que acontece esse conflito. J√° pensando nesse casso, resolvi implementar dessa forma.

# üõ† Tecnologias Utilizadas

üîπ Back-end:
Node.js: Ideal para opera√ß√µes que utilizam streams e entrada/sa√≠da de dados.
Fastify: APIs leves e r√°pidas. Melhor suporte ao TypeScript. Alto modularidade e isolamento de escopo com plugins.
Streams nativas do Node.js: para processar arquivos sem sobrecarregar a mem√≥ria.
Prisma ORM: (armazenamento otimizado)

üîπ Infraestrutura:
Docker + Docker Compose: para facilitar a orquestra√ß√£o dos servi√ßos.
Redis: cache para otimizar buscas frequentes.
RabbitMQ: mensageria para distribuir tarefas entre os workers.
MySQL: Banco de dados relacional utilizado para armazenar dados estruturados.
MinIo: Armazenamento de objetos auto-hospedado e totalmente compativel com o s3. Ideal para ambientes de desenvolvimento.

üîπ Testes:
Vitest: testes unit√°rios e de integra√ß√£o

# Estrutura do Projeto (arquitetura)
Nesse projeto segui uma padroniza√ß√£o nas pastas para deixar o c√≥digo mais modular poss√≠vel e f√°cil de extender. Tamb√©m segui bons princ√≠pios na escrita do c√≥digo, usando SOLID, clean architecture.
Foi mais ou menos assim como pensei:
### Camada de aplica√ß√£o: 
Os use-cases orquestram as regras de neg√≥cio e fazem chamadas para o repository.
Alguns exemplos de como funciona:
- `create-customer`: Conhece a l√≥gica para criar um cliente.
- `create-order`: Conhece a l√≥gica para criar um pedido.
   - Nesse use case, por exemplo, existe a necessidade de que o cliente exista antes de voc√™ criar um pedido para ele. Ent√£o, √© necess√°rio chamar algu√©m externo para fazer essa valida√ß√£o, ou seja, consultar o banco de dados, mas o use case n√£o pode acessar o banco de dados diretamente, ent√£o ele pede para o repository fazer isso. A camada de aplica√ß√£o se comunica com coisas externas, mas n√£o faz isso diretamente, sempre usa uma interface de comunica√ß√£o.
- `get-order`: Conhece a l√≥gica para recuperar os dados de um pedido, mas precisa comunicar com o mundo externo usando os repositories para buscar esses dados no banco de dados.

### Camada de dom√≠nio:
E nas entities que as regras de neg√≥cio deveriam estar e elas n√£o podem depender de coisas externas, apenas pontos centrais do neg√≥cio.

### Camada de infra/adapters:
Coloquei tantos os controllers quanto as implementa√ß√µes dos repositories aqui. Nessa pasta √© onde a comuni√ß√£o entre o sistema e o mundo externo acontece.
Uma interface de comunica√ß√£o com o mundo pode ser o controller que receber requisi√ß√µes http e chama os casos de uso.
Podemos essa organiza√ß√£o acontecendo no PrismaCustomerRepository que impletamenta o CustomerReposity usando o prisma para se comunicar com o banco de dados, essa impleta√ß√£o deve acontece quando estamos pensando na infra.
Tamb√©m temos nessa pasta arquivos como o `ordersRoutes` dentro dessa pasta que conecta os controllers do o framework fastify.

A separa√ß√£o garante que o Dom√≠nio e Aplica√ß√£o n√£o dependam da infraestrutura, tornando o c√≥digo mais modular, test√°vel, f√°cil de evoluir e agn√≥stico ao framework.

![system design](images/pastas.jpg)

# Decis√µes T√©cnicas e Arquiteturais

1. Optei por usar um ORM pela facilidade de integra√ß√£o com o banco de dados e por deixar o c√≥digo mais leg√≠vel e intuitivo. A grande vantagem de usar um ORM √© que ele traz agilidade nas opera√ß√µes com o banco de dados, oferecendo abstra√ß√µes para CRUDs, por exemplo. Isso elimina grande parte da necessidade de escrever query manuais. Essas vantagens me permitiram gastar mais tempo em desenvolver uma boa arquitetura de microsservi√ßos. Al√©m disso, o Prisma ORM permite integra√ß√£o com diferentes bancos de dados sem grandes altera√ß√µes, seguran√ßa com valida√ß√£o de dados embutida, al√©m de entregar uma melhor developer experience para manuten√ß√£o do c√≥digo.
2. Usar princ√≠pios de SOLID e clean architecture permitiu que o c√≥digo fosse menos acoplado, mais test√°vel, extens√≠vel e manuten√≠vel. Com isso, n√£o ser√° dif√≠cil adicionar novas funcionalidades ao sistema.
3. Uma das partes mais desafiadoras com certeza foi os microsservi√ßos, transformar todo esse processamento de arquivos desnormalizados em uma opera√ß√£o ass√≠ncrona, com filas e streams de dados, permitiu que m√∫ltiplos arquivos fossem processados sem nenhuma perda de dados. Al√©m de que, agora, podemos facilmente adicionar mais processos nesse fluxo, com outros tipos de opera√ß√£o e at√© mesmo linguagens de programa√ß√£o diferentes para os workers.
4. A escolha de dividir em dois microsservi√ßos veio pela facilidade de integrar um novo worker no fluxo para, por exemplo, processar esses arquivos e gerar outro tipo de sa√≠da.
5. A Escolha do RabbitMQ foi por ele ser um servi√ßo de message broker, leve, confi√°vel e escal√°vel. O RabbitMQ oferece tudo isso, melhorando a resili√™ncia da aplica√ß√£o e evitando a perda de mensagens, j√° que ele trabalha com o conceito de acknowledgment e retry.
6. Usei o docker no projeto, pois ele permite a orquestra√ß√£o dos servi√ßos e garante que o ambiente seja id√™ntico em todas as m√°quinas e servidores. Al√©m de facilitar a escalabilidade com containers isolados.
7. O MinIO permite criar um ambiente 100% compat√≠vel com o s3, mas na sua M√ÅQUINA LOCAL, isso fez todo o sentido para o desenvolvimento e em produ√ß√£o n√£o precisamos nenhuma configura√ß√£o adicional.

   
# ‚úÖ Vantagens da Arquitetura Atual
Desacoplamento ‚Üí O servi√ßo que l√™ o arquivo n√£o precisa saber quem vai processar as linhas, tornando o sistema mais modular.

Escalabilidade ‚Üí Se houver muitos arquivos ou linhas, basta aumentar a quantidade de consumidores (workers) para processar mais r√°pido.

Toler√¢ncia a falhas ‚Üí Se um consumidor cair, as mensagens ficam na fila e podem ser processadas assim que ele voltar.

Balanceamento de carga ‚Üí RabbitMQ distribui as mensagens entre os consumidores ativos, evitando sobrecarga em um √∫nico servi√ßo.

Retry autom√°tico ‚Üí Se um consumidor falha ao processar uma linha, a mensagem pode ser reenviada para ser processada novamente.

# üìà Benef√≠cios para o Neg√≥cio
Aumento de Capacidade ‚Üí Com a fila desacoplando leitura e processamento, a empresa pode lidar com arquivos maiores sem travar o sistema.

Redu√ß√£o de Custos ‚Üí Como o processamento fica distribu√≠do, √© poss√≠vel escalar apenas onde for necess√°rio, evitando desperd√≠cio de infraestrutura.

Entrega mais r√°pida ‚Üí Processamento paralelo significa que resultados chegam antes, melhorando a experi√™ncia do usu√°rio.

# üöÄ Melhorias Futuras
üìå Adi√ß√£o de suporte a outros formatos de arquivo (JSON, XML).
üìå Monitoramento de fila no Prometheus + Grafana.


# Imagem do System Design
![system design](images/system-design.png)

## üîç Fluxo de Processamento
**Upload de Arquivo**: O usu√°rio envia um arquivo desnormalizado via API Fastify.
**Processamento na API**: O arquivo √© enviado para o MinIO para ser armazenado e acessado posteriormente, os meta dados do arquivo s√£o salvos no MySQL e uma mensagem com o id od arquivo √© p√∫blica na fila PROCESS.FILES.
**No worker process files**: O arquivo √© recuperado do bucket, lido em chunks e os dados s√£o processados utilizando Streams, o que torna o uso de RAM baix√≠ssimo. Posteriormente, uma mensagem √© publicada na fila PROCESS.ROWS com a linha crua. Cada linha √© enviada para um microsservi√ßo via RabbitMQ para processamento ass√≠ncrono.
**Enfileiramento com RabbitMQ**: As partes do arquivo processado s√£o enviadas para RabbitMQ, que distribui as tarefas entre os workers dispon√≠veis.
No worker process rows: Cada linha √© recebida, processada e validada de maneira que n√£o ocorra perdas. Esse worker faz chamadas via http para a API para salvar cada linha no banco de dados. Como trabalhamos com IDs √∫nicos no banco de dados, nenhum dado √© duplicado.
Armazenamento: Dados estruturados s√£o armazenados no MySQL.

# Autor
**Nome**: Leander Silveira Santos
**LinkedIn**: https://www.linkedin.com/in/leander-silveira/
**Github**: https://github.com/leander34

